# 운영체제(OS)

## Process(프로세스)

컴퓨터에서 연속적으로 실행되고 있는 컴퓨터 프로그램

### 프로세스 생성

- 시스템 초기화
- 실행중인 프로세스가 프로세스 생성 시스템 호출을 수행한 경우
- 사용자 요청에 의해
- 배치 작업의 시작

### 프로세스 종료

- 정상종료(자발적)
- 오류종료(자발적)
- 치명적 오류(비자발적)
- 다른 프로세스에 의해 종료(비자발적)

### 프로세스 상태

![Untitled](https://user-images.githubusercontent.com/44499629/119229771-63be6080-bb54-11eb-9af1-f3be006d1de3.png)


**new : 프로세스 생성중**

- 프로세스를 생성하고 있는 단계로 커널에 PCB가 만들어진 상태

**ready : 프로세스가 CPU를 기다리는 상태**

- 프로세스가 메모리에 적재된 상태로 실행하는데 필요한 자원을 모두 얻은 상태
- 즉, CPU만 할당받으면 바로 실행 가능한 상태
- ready 상태를 가진 프로세스가 여러개 존재할 수 있다(queue)

**running : 프로세스가 CPU를 할당받아 명령어를 수행중인 상태**

- CPU가 하나일 때(다중 코어, 스레드 제외) CPU를 할당받아 실행중인 프로세스는 한개

**blocked : 프로세스가 CPU를 할당받아도 실행할 수 없는 상태**

- 프로세스가 I/O 처리 등 다른 작업을 처리중이기 때문에 다음 명령어를 수행할 수 없는 상태

**terminated : 프로세스의 실행 종료**

- 프로세스 실행이 완료되고 할당받은 CPU를 반납, 커널 내 PCB는 남아 있음

**suspended : 프로세스의 중지 상태**

- 메모리를 강제로 뺏긴 상태로 특정한 이유로 프로세스 수행이 정지된 상태
- 외부에서 다시 재개시키지 않는 이상 다시 활성화가 될 수 없음
- 대표적인 예로 '디스크로 스왑 아웃된 프로세스의 상태'

## PCB(Process Control Block) : 프로세스 테이블

- 특정한 프로세스에 대해 관리할 필요가 있는 정보를 포함하는 운영체제 커널의 자료구조
- 프로세스가 생성될 때 마다 고유의 PCB를 생성
- Context Switch가 발생하면 진행중인 프로세스의 작업을 중단하고(Interrupt 발생), CPU를 반환해야 하는데, 이때 처리하던 작업에 대한 내용을 PCB에 저장
- PID(Process Id), 프로세스 상태, PC(program counter), cpu 레지스터/일반 레지스터, CPU 스케쥴링 정보(우선순위, 최종실행시간, CPU 점유 시간), 메모리 관리 정보(해당 프로세스의 주소 공간), 프로세스 계정 정보(페이지 테이블, 스케쥴링 큐 포인터 등), 입출력 상태 정보(프로세스에 할당된 입출력 장치 목록, 열린 파일 목록)

**PCB에 저장되는 정보**

- 프로세스 식별자(Process ID, PID) : 프로세스 식별번호
- 프로세스 상태 : new, ready, running, waiting, terminated 등의 상태를 저장
- 프로그램 카운터 : 프로세스가 다음에 실행할 명령어의 주소
- CPU 레지스터
- CPU 스케쥴링 정보 : 프로세스의 우선순위, 스케줄 큐에 대한 포인터 등
- 메모리 관리 정보 : 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보를 포함
- 입출력 상태 정보 : 프로세스에 할당된 입출력 장치들과 열린 파일 목록
- 어카운팅 정보 : 사용된 CPU 시간, 시간제한, 계정번호 등

## 인터럽트(Interrupt)

CPU가 수행중 다른 일을 급하게 처리하고자 할때 사용할 수 있는 기능이다. 대부분 컴퓨터는 한 개의 CPU를 사용하므로 한 순간에 하나의 일 밖에 처리할 수 없다. **어떤 일을 처리하는 도중에 우선순위가 급한 일을 처리할 필요가 있을 때 대처할 수 있는 방법이 Interrupt이다.**

### 인터럽트 종류

- **외부 인터럽트(하드웨어) : 입출력 장치, 타이밍 장치, 전원 등의 외부적인 요인에 의해서 발생하는 인터럽트.**
  - 전원 이상 인터럽트 : 정전이나 전원이 이상있는 경우
  - 기계 고장 인터럽트 : CPU등의 기능적인 동작 오류가 발생한 경우
  - 입출력 인터럽트(I/O Interrupt) : 입출력의 종료 등의 이유로 CPU의 수행을 요청하는 인터럽트.
  - 타이머 인터럽트 : 대표적인 예로 선점형 스케줄러에서 사용(일정 시간동안만 CPU를 할당, 시간 초과 시 교체)
- **내부 인터럽트(소프트웨어) : 잘못된 명령이나 데이터를 사용할 때 발생하는 인터럽트**
  - 0으로 나누는 경우
  - 오버플로우/언더플로우
  - 프로그램상의 오류
  - 프로그램에서 함수 등 명령어를 잘못 사용한 경우
  - CPU가 명령어 수행 도중 발생하는 인터럽트

**외부 인터럽트**는 CPU의 클럭 신호와 관계 없이 발생하기 때문에 `비동기적 인터럽트`이다. **내부 인터럽트**는 소프트웨어적으로 CPU의 명령어를 실행하는 과정에서 발생하는데, 해당 명령어의 실행을 마치고 난 다음에만 인터럽트를 발생시킨다. 따라서 `동기적 인터럽트`이다. 

### 인터럽트 과정

- Process A 실행 중 딬스크에 어떤 데이터를 읽어오라는 명령을 받은 경우
    1. Process A는 System Call을 통해 인터럽트 발생
    2. CPU는 현재 진행중인 기계어 코드(명령어) 수행 완료
    3. 현재까지 수행중이던 상태를 해당 Process의 PCB에 저장
    4. PC에 다음 수행할 명령어 주소 저장
    5. 인터럽트 벡터를 읽고 ISR(Interrupt Service Routine) 주소값을 얻어 점프 후 루틴 실행
    6. 해당 루틴 완료 후 대피시킨 레지스터 복원
    7. ISR 마지막에 IRET 명령어가 인터럽트를 해제
    8. IRET명령어 실행 후 PC값 복원


## 스레드(Thread)

`프로세스의 실행 단위` , 한 프로세스 내에서 동작되는 여러 실행 흐름으로 프로세스 내의 주소공간이나 자원을 공유할 수 있다. 

- 스레드는 스레드 ID, 프로그램 카운터, 레지스터 집합, 그리고 스택으로 구성
- 같은 프로세스에 속한 다른 스레드와, 코드, 데이터섹션, 그리고 열린 파일이나 신호와 같은 운영체제 자원을 공유한다.
- 하나의 프로세스를 다수의 실행단위로 구분하여 자원을 공유하고 자원의 생성과 관리의 중복성을 최소화하여 수행 능력을 향상시키는것을 `멀티 스레딩` 이라 한다. `멀티 스레딩`의 경우 각각의 스레드가 독립적인 작업을 수행해야 하기 때문에 스택, PC, 레지스터를 각각 가지고 있다.
- 프로세스보다 가벼워 생성/종료가 쉽고 빠르다.
- 많은 연산과 많은 I/O가 동시에 존재하는 경우 성능 향상(I/O Bounded)

**스택, PC(Program Counter)를 스레드마다 독립적으로 할당하는 이유**

- 스택은 함수 호출 시 전달되는 인자, 되돌아갈 주소값 및 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간이다. 즉 독립적인 함수 호출이 가능하기 위해서는 각각의 스택이 존재해야 하고, 즉 독립적인 실행 흐름이 추가되는 것이다.
- PC는 스레드가 다음 실행할 명령어의 주소를 가르킨다. 즉 스레드별로 어디까지 수행되었는지 저장해야 하기 때문에 각각의 프로세스별로 존재해야 한다.

## 스레드 패키지 구현

### User Level Thread

장점

- 커널은 해당 스레드를 단일 프로세스로 인식
- 스레드를 지원하지 않는 운영체제에서도 구현 가능
- 트랩x, 문맥교환x, 메모리 캐쉬 flush x ⇒ 스케쥴링이 빠르다 / 확장적, 효율적

단점

- Blocking System Call(입출력) 사용 ⇒ 프로세스 정지 ⇒ 모든 스레드가 정지될 수 잇다.
- 호출이 블록될지 미리 알 수 있다면 다른 대안으로 해결 가능, 예를 들어 select 시스템 ㅎ출을 통해 read가 대기될 지 알려주고 이후 read 수행(이러한 로직, 코드를 wrapper, 자켓 이라 부른다)
- 페이지 폴트가 발생하면 프로세스 전체가 블록된다
- 자발적으로 CPU 양보가 불가능하다(클록 인터럽트 사용 불가)

### Kernel Level Thread

장점

- 커널 시스템 내부에 스레드 테이블이 존재한다.
- 시스템 호출 비용이 저렴(스레드 재활용 가능 - 커널에 자료구조를 남겨 놓기 때문)
- 프로세스 블록으로 야기되는 문제가 없음

단점

- fork 시 스레드 전부 복사
- 시그널(프로세스에 전달) 어떤 스레드가 처리할지, 둘 이상 시그널이 발생했을 때 문제가 생김

---

## 프로세스 간 통신

- 경쟁 조건(Race Condition) : 공유 자원(메모리, 파일 등)에 대한 동시 접근 문제
    - 임계 구역(Critical Region) : 공유 메모리를 접근하는 프로그램의 부분(서로 다른 프로세스(프로그램)끼리 영향을 미칠 수 있는 부분)
    - 상호 배제(Mutual Exclusion) : 한 프로세스가 공유 변수나 파일을 사용중이면 다른 프로세스들은 똑같은 일을 수행하지 못하도록 하는 기법
- 4가지 조건
    1. 두 프로세스가 동시에 자기의 임계구역 내에 존재하는 경우는 없어야 한다.
    2. CPU 개수, 속도 어떠한 가정도 하지 않는다.
    3. 임계구역 외부에서 실행되고 있는 프로세스는 다른 프로세스를 블록시켜선 안된다.
    4. 임계구역에 진입하기 위해 무한히 기다리는 프로세스는 없어야 한다.

## Busy Waiting(바쁜 대기)를 사용한 상호 배제 기법

### 1. 인터럽트 끄기

- 임계구역에 진입하자마자 인터럽트를 끄고 완료 후 다시 킨다. → 문맥교환을 방지함, 하지만 해당 CPU에만 적용되며 위험이 존재한다.

### 2. 락(Lock) 변수

- 소프트웨어 해법
- 임계구역에 들어가기 전에 Lock변수 확인 → 0일때 1로 변경하면서 임계구역 진입

문제점(상황)

1. 한 프로세스가 Lock 변수를 확인 후 1로 변경하기 전에 블록
2. 다른 프로세스가 Lock변수가 아직 1로 바뀌지 않은 0을 보고 임계구역 진입
3. 이후 이전 프로세스가 다시 스케줄되어 Lock을 확인했으니 1로 변경하면서 진입
4. 2개의 프로세스가 임계구역에 진입하게 됨

Busy Waiting을 하며 lock이 반환될 때 까지 계속 확인하며 기다리는 기법은 `Spin Lock`

### 3. 엄격한 교대(Strict Alteration)

![Untitled](https://user-images.githubusercontent.com/44499629/119512816-a24f5780-bdae-11eb-8f56-e2ff7dbd7762.png)

두 프로세스가 공유변수 turn값을 기준으로 임계구역에 진입할지 결정한다. 프로세스 a는 turn값이 0이 될때 까지 무한루프를 돌며, 프로세스 b는 turn값이 1이 될때 까지 무한루프를 돈다. 즉 프로세스 a는 turn = 0일때 반복문을 진입하여 critical_region()함수를 통해 임계구역에 진입한다. 수행 이후 turn값을 1로 변경해 프로세스 b가 임계구역에 진입할 수 있도록 한다.

**문제점(조건3 위반 : 임계구역에 없는 프로세스에 의해 블록될 수 있다)** : 프로세스 a가 turn = 1 로 변경 후 다시 임계구역에 진입하기 위해서는 프로세스 b가 무조건 임계구역에 진입 후 turn = 0으로 변경해주어야만 한다. 즉 프로세스 b 가 수행되기 전까지 절대 임계구역에 진입할 수 없게 된다. 또한 무한 루프를 돌며 (Busy waiting) 자원(CPU)을 낭비한다. 시간이 짧게 소요된다는 합리적인 예상이 가능한 경우에만 사용한다.

### 4. TSL 명령어 (Test and Set Lock)

메모리 워드 Lock 값을 읽어 레지스터에 저장하고 메모리 주소 Lock엔 0이 아닌 값을 저장한다. 이 명령어는 atomic하기 때문에 이 연산이 종료될 때까지 어떠한 처리기도 메모리 워드에 접근할 수 없다.(메모리 버스를 잠금)

단점

- Busy Waiting → CPU낭비, 우선순위 역전 문제(우선순위가 높은 작업이 Busy Waiting 중이라 다른 작업 먼저 수행할 경우) 발생

### 5. Sleep and Wake Up

- Busy Waiting으로 인한 CPU 낭비를 없앨 수 있다.
- Sleep : 호출자를 블록상태로 만드는 시스템 호출(다른 포로세스가 깨워줄 때 까지)
- Wake Up : 깨울 프로세스를 가르키는 인자

생산자,소비자 문제

### 6. Mutex & Semaphore(세마포어)

- Counting Semaphore
    - 가용한 개수를 가진
    - 세마포어를 소유하지 않는 스레드가 세마포어를 해제할 수 있다.
    - 세마포어는 소유할 수 없다.
    - 시스템 범위에 걸쳐있고 파일 시스템상의 파일 형태로 존재한다.
    - down : 0보다 크면 감소 → 수행 / 0이면 Sleep (atomic)
    - up : 세마포어에 잠들어 있는 프로세스가 있을 경우 down을 수행 시킴
    - 위 명령어들을 시스템 호출 형태로 구현, TSL명령어 활용
    - **생산자/소비자 문제** 해결 : 3개의 세마포어 사용(full = 0, empty = 빈 슬롯 개수, mutex = 1 로 초기화
        - `생산자 소비자 문제` : 두 프로세스가 고정된 크기의 버퍼를 공유할 때 발생하는 문제.
            - 해결책 : 꽉 찼을때 생산자는 잠들고 소비자가 하나를 꺼낼때 생산자를 깨워준다. 꺼내려고 할 때 비어있으면 소비자가 잠들고 생산자가 넣고 깨워준다. 버퍼 크기를 나타내는 count 변수를 활용한다.
            - 경쟁 조건이 발생할 수 있다. → count에 대한 접근 제한이 없기 때문(Wakeup waiting 비트를 활용한다.)
        - full : 아이템으로 채워진 슬롯의 개수
        - empty : 빈 슬롯의 개수
        - mutex : 생산자와 소비자가 둘다 동시에 버퍼에 접근 못하게 함
- Binaray Semaphore
    - `Mutex`라고도 부르며, 상호배제(`Mutual Exclusion`)의 머릿글자를 따서 만들어졌다.
    - 상태값이 0과 1로만 이루어져 있다.
    - 뮤텍스를 소유하고 있는 스레드만이 뮤텍스를 해제할 수 있다.
    - 프로세스 범위를 가지며 프로세스가 종료될 때 자동으로 clean up 된다.

가장 큰 차이점은 관리하는 **동기화 대상의 갯수**이다**. `Mutex`는 동기화 대상이 오직 하나뿐일 때, `Semaphore`는 동기화 대상이 하나 이상일 때 사용한다.**

### 8. Monitor(모니터)

- 모듈 또는 패키지에 모아진 프로시져, 변수, 자료구조의 모음
- 모니터 밖의 프로시져에서 모니터 내부 자료구조 접근 불가능
- 단 하나의 프로세스만 한순간에 모니터에서 활동할 수 있다.

---

## 스케줄링

> 둘 이상의 프로세스(스레드)가 단 하나의 CPU를 사용할 수 있을 때 프로세스 선택 방법, CPU의 효율적인 사용을 위해 쓰인다.

- CPU Bound Process → CPU 수행시간이 길다.
- I/O Bound process → CPU 수행시간이 짧다.

**스케줄링이 발생하는 경우**

1. 새로운 프로세스를 만들 때 자식 프로세스를 먼저 실행할 것인지, 부모 프로세스를 먼저 실행할 것인지 결정할 때
2. 프로세스 종료할 때 → 준비된(Ready) 프로세스 중 선택
3. 프로세스가 I/O, 세마포어, 혹은 다른 이유로 무언가에 의해 대기(Block)해야 할 때
4. I/O Interrupt 발생했을 때

**클록 인터럽트를 어떻게 다루냐에 따라**

- 비선점 스케줄링 알고리즘
    - 클록 인터럽트에 의해 스케줄링 x (자발적으로 CPU를 반환하기 전까지 **뺏을 수 없다**.)
- 선점 스케줄링 알고리즘
    - 정해진 시간이 지나면 스케줄러 작동(클럭 인터럽트에 의해)

**환경에 따라**

- 배치
    - 처리량(처리율 : 시간당 처리된 작업의 개수)
    - 반환시간(작업 시작 후 끝날때 까지 걸린 시간)
    - CPU 이용률
- 대화식 : 선점이 필수적(사용자 여려명 - 공평해야한다.), 응답시간 최소화
- 실시간

### 배치 시스템 스케줄링

**FCFS(선입선출)**

- 프로세스들을 요청 순서대로 CPU를 할당하는 기법
- 단일 큐 존재(Ready Process)
- 장점
    - 구현이 쉽다.
- 단점
    - 초기에 I/O bound Process가 할당되면 너무 오래 걸린다(뒤에 빠르게 끝낼 수 있는 프로세스들도 전부 기다려야 한다)

**SJF(Shortest Job First)**

- 각 프로세스들의 실행시간을 안다는 가정 & 모든 작업이 동시에 존재할 때 최적의 이상적인 스케줄링
- 작업의 도착시간이 다를 경우 최적이 아닐 수 있다.
    - ``` 
       A : 작업시간 2, 도착시간 0

       B : 작업시간 4, 도착시간 0

       C : 작업시간 1, 도착시간 3

       D : 작업시간 1, 도착시간 3

       E : 작업시간 1, 도착시간 3 
       ```

    - **SJF** 작업 순서 : A → B (C, D, E 도착 전이기 때문에) → C → D → E 

      평균 반환 시간 (2 + 6 + 4 + 5 + 6) / 5 = 4.6

    - 최적 : B → C → D → E → A

      평균 반환 시간 (9 + 4 + 2 + 3 + 4) / 5 = 4.4

**SRTN(Shortest Remaing Time Next) : 최단 잔여 시간 우선**

- SJF와 마찬가지로 각 프로세드들의 필요한 실행 시간을 알고 있어야 한다.

### 대화식 시스템 스케줄링

**Round-Robin**

- 시간 할당량(time quantum)이라는 시간 주기가 할당된다.
- 시간 할당량만큼 수행 후 스케줄링(그전에 끝나도 교체)
- 할당시간이 짧으면 문맥교환이 빈번히 발생 → CPU 효율 저하
- 할당시간이 길면 응답시간이 길어진다.
- 20~50 sec가 합리적
- FCFS처럼 큐 사용(+ 시간 할당량) : 시간할당량 이후 맨 뒤로 이동
- Response Time은 좋지만 Turnaround Time은 좋지 않다.

**Priority Scheduling**

- 각 프로세스별로 우선순위를 할당하여 높은 순서대로 수행
- 높은 우선순위의 프로세스가 무한히 실행되는 상황(`Starvation 기아 현상` - 낮은 우선순위의 프로세스들이 계속 CPU를 할당 못받는 경우)을 막기 위해 스케줄러는 `클록 인터럽트` 마다 현재 실행중인 프로세스의 우선순위를 낮출 수 있다. (`Aging 기법`)
- 우선순위 별로 RR 적용과 같음
- 우선순위 = 할당시간 / 소비시간

**Multi Level Feedback Queue**

- 우선순위 스케줄링과 비슷하나 우선순위별로(Queue) 시간 할당량을 달리 함
- 우선순위가 높은 큐는 시간 할당량을 짧게 가져감

규칙

- 규칙 1 : 우선순위가 높은 프로세스들을 먼저 수행한다.
- 규칙 2 : 작업들이 같은 우선순위를 갖는다면 RR로 수행한다.
- 규칙 3 : 새로운 프로세스가 시스템에 들어가면 가장 높은 우선순위를 부여한다.
- 규칙 4 : 작업은 모든 우선순위에서 주어진 time slice를 모두 사용하면 우선순위가 감소한다.
- 규칙 5 : 일정 시간 후 시스템의 모든 작업을 우선순위가 가장 높은 큐로 이동한다.

---

## 메모리 관리

- 여러 프로그램을 동시에 메모리에 적재하고 서로 간섭없이 실행하기 위해 보호(protection)와 재배치(relocation)
- 주소공간 : 메모리 추상화 ⇒ 동적 재비치(Dynamic Relocation) : Base, Limit 레지스터 사용(오직 OS만 변경 가능)
    - Base 레지스터 : 프로그램이 할당받은 메모리의 시작 위치
    - Limit 레지스터 : 프로그램의 크기

### 메모리 관리 기법

1. **Swapping(스와핑)**
    - 한 프로세스의 `모든 이미지`가 메모리로 적재(**Swap In**)되었다가 더이상 실행되지 않을 경우 다시 디스크로 보냄(**Swap Out**)
    - Swap In 될 때 메모리 재배치 필요(주소), 빈공간 모음(메모리 조각 모음)
    - **단편화(Fragmentation)**
        - 프로세스들이 메모리에 적재되고 제거되는 일이 반복되다보면, 프로세스들이 차지하는 메모리 틈 사이에 사용하지 못할 만큼의 작은 자유공간들이 늘어나게 되는데, 이것을 단편화라고한다.
        - **외부 단편화** : 메모리 공간 중 사용하지 못하게 되는 일부분. 물리 메모리(RAM) 사이사이 남는 공간들을 모두 합치면 충분한 공간이 되는 부분들이 분산되어 있을 때 발생한다고 볼 수 있다.
        - **내부 단편화** : 프로세스가 사용하는 메모리 공간에 포함된 남는 부분. 예를들어 **메모리 분할 자유 공간이 10000B 있고 Process A 가 9998B를 사용하게 되면 2B라는 공간이 남고**, 이를 내부 단편화라고 한다.
        - 압축 : 외부 단편화를 해결하기 위해 프로세스가 사용하는 공간들을 한쪽으로 몰아 자유공간을 확보하는 방법이지만 **작업 효율이 좋지 않다.**
2. **Virtual Memory(가상 메모리)**
    - 한 프로세스의 `일부 이미지` 만 메모리에 적재
    - 메모리의 어느 부분이 사용중인지 관리 필요
        - 비트맵 → 메모리 할당 단위마다 비트 대응(1 - 사용, 0 - 사용 x)
            - 메모리 할당 단위를 크게하면 비트맵 공간이 작아진다. 하지만 마지막 할당단위의 일부 공간이 낭비된다.
            - 메모리 할당 단위를 작게하면 비트맵 공간이 커진다. 공간이 커 비트 검색 시간이 많이 걸린다.
        - 리스트
            - 프로세스 내용, 시작 주소, 길이, 다음엔트리를 가르키는 포인터로 구성

    **메모리 할당 방법**

    1. First fit
        - 리스트 순서대로 빈공간을 찾아 담을 수 있으면 할당
        - 남은 부분은 빈공간으로 ⇒ 검색 최소화(빠름)
    2. Next fit
        - 마지막으로 할당된 위치 부터 검색
        - First fit 보다 성능 떨어짐
    3. Best fit
        - 처음부터 끝까지 모든 빈공간을 검색하여 최적의 공간을 선택한다.
        - 느리다, 낭비 메모리가 더 많다.
    4. Worst fit
        - 가장 큰 공간에다가 할당

### 메모리 관리방법

### Paging(페이징)

하나의 프로세스가 사용하는 메모리 공간이 연속적이여아 한다는 제약을 없애는 메모리 관리 기법이다.

외부 단편화와 압축 작업을 해소하기 위해 생긴 방법론으로, **물리메모리**는 `Frame`이라는 고정 크기로 분리되어 있고, **논리 메모리**(프로세스가 점유하는)는 `페이지`라 불리는 고정 크기의 블록으로 분리된다.(페이지 교체 알고리즘에 들어가는 페이지)

페이징 기법을 사용함으로써 논리 메모리는 물리 메모리에 저장될 때, 연속되어 저장될 필요가 없고 매핑만 시켜주면 된다. 따라서 물리 메모리의 남는 프레임에 적절히 배치시킴으로써 외부 단편화를 해결할 수 있는 큰 장점이 있다.

하나의 프로세스가 사용하는 공간은 여러개의 페이지로 나뉘어서 관리되고(논리 메모리에서), 개별 페이지는 순서에 상관없이 물리 메모리에 있는 프레임에 mapping되어 저장된다.

- 단점 : 내부 단편화 문제 발생
    - 프로세스가 필요한 공간이 4개 페이지 프레임이 필요하지만 마지막 프레임에서 공간이 남을 수 있다. (꽉 찬 경우 제외)

### Segmentation(세그멘테이션)

페이징처럼 물리 메모리와 논리 메모리를 같은 크기의 블록이 아닌, 서로 다른 크기의 논리적인 단위인 세그먼트(Segment)로 프로세스를 나눠 사용

- 장점
    - 증가, 감소 가능(가변 크기)
    - 링킹 작업 단순
    - 해당 세그먼트만 변경 가능
    - 공유가 쉽다.
- 단점
    - 동적 할당(외부 단편화 발생)

## 가상 메모리

가상메모리는 프로세스 전차가 메모리 내에 올라오지 않더라도 실행 가능하도록 하는 기법.

다중 프로그래밍을 실현하기 위해 많은 프로세스들을 동시에 메모리에 올려두어야 한다. 이를 가능하게 하며 프로그램이 물리 메모리보다 커도 된다는 장점이 있다.

### 가상 메모리 개발 배경

실행되는 코드의 전부를 물리 메모리에 올려야 했고, **메모리 용량보다 큰 프로그램은 실행시킬 수 없었다**. 또한 여러 프로그램을 동시에 메모리에 올리기에는 **용량의 한계**와, **페이지 교체 등의 성능 이슈**가 발생하게 된다. 또한, **가끔만 사용되는 코드가 차지하는 메모리들**을 확인할 수 있다는 점에서 불필요하게 전체의 프로그램이 메모리에 올라와 있어야 하는게 아니라는 것을 알 수 있다.

- 물리 메모리 크기에 제약을 받지 않게 된다
- 더 많은 프로그램을 동시에 실행할 수 있게 되며 응답시간은 유지되고, `CPU 이용률`과 `처리율`이 높아진다.
- `Swap`(전체 In, Out)에 필요한 입출력이 줄어들기 때문에 프로그램들이 빠르게 실행된다.

### 가상 메모리가 하는 일

가상 메모리는 실제의 물리 메모리 개념과 사용자의 논리 메모리 개념을 분리한 것. 작은 메모리를 가지고도 얼마든지 큰 **가상 주소 공간을** 프로그래머에게 제공할 수 있다.

**가상 주소 공간**

- 한 프로세스가 메모리에 저장되는 논리적인 모습을 가상메모리에 구현한 공간이다. 프로세스가 요구하는 메모리 공간을 가상메모리에 제공함으로서 현재 직접적으로 필요하지 않은 메모리 공간은 실제 물리 메모리에 올리지 않게하여 절약할 수 있다.

**프로세스간 페이지 공유**

- `시스템 라이브러리`가 여러 프로세스들 사이에서 공유될 수 있도록 한다. 각 프로세스들은 공유 라이브러리를 `자신의 가상 주소 공간`에 두고 사용하는 것처럼 인식하지만, 라이브러리가 올라가 있는 `물리 메모리 페이지`들은 모든 프로세스에 **공유**되고 있다.
- 프로세스들이 메모리를 공유하는 것을 가능하게 하고, 프로세스들은 공유 메모리를 통해 통신할 수 있다. 이 또한 각 프로세스들은 자신의 주소공간으로 인식하지만, 실제 물리 메모리는 공유되고 있다.
- `fork()`를 통한 프로세스 생성 과정에서 페이지들이 공유되는 것을 가능하게 한다.

### Demand Paging(요구 페이징)

프로그램 실행 시작 시에 프로그램 전체를 디스크에서 물리메모리에 적재하는 대신, 초기에 필요한 것들만 적재하는 전략을 `요구 페이징`이라 한다. 요구페이징을 사용하는 가상 메모리에서는 실행과정에서 필요해질 때 페이지들이 적재된다. 한번도 접근하지 않은 페이지는 물리 메모리에 적재되지 않는다.

프로세스 내의 개별 페이지들은 `페이저(pager)`에 의해 관리된다. 페이저는 프로세스 실행에 실제 필요한 페이지들만 메로리로 읽어 온다. **사용되지 않을 페이지를 가져오는 시간낭비와 메모리 낭비를 줄일 수 있다.**

### 페이지 교체

프로세스 동작에 필요한 페이지를 요청하는 과정에서 물리 메모리에 올라와있지 않으면 `page fault(페이지 부재)`가 발생한다. 이후 페이지를 보조저장장치에서 가져오게 된다. 하지만, 만약 **물리 메모리가 모두 사용중**이라면, `페이지 교체`가 이뤄져야 한다.(또는 운영체제가 프로세스를 강제 종료하는 방법이 있다.)

**기본적인 방법**

물리 메모리가 모두 사용중일 때 메모리 교체 흐름

1. 디스크에서 필요한 페이지의 위치를 찾는다.
2. 빈 페이지 프레임을 찾는다.(교체할)
    1. **페이지 교체 알고리즘**을 통해 희생될(victim) 페이지(교체할)를 고른다.
    2. 희생될 페이지를 디스크에 기록하고, 관련 페이지 테이블을 수정한다.
3. 새롭게 비워진 페이지 테이블 내 프레임에 새 페이지를 읽어오고, 프레임 테이블을 수정한다.
4. 사용자 프로세스 재시작

### 페이지 교체 알고리즘

**FIFO 페이지 교체**

First In First Out의 약자로 먼저 물리 메모리에 들어온 페이지 순서대로 페이지 교체 시점에 먼저 나가게 된다.

- 장점
    - 구현이 쉽다.
- 단점
    - 오래된 페이지가 항상 필요한 정보를 가지지 않을 수 있다.
    - 처음부터 활발하게 사용되는 페이지를 교체해서 `page fault`를 빈번히 발생시키는 부작용을 초래할 수 있다.
    - `Belady의 모순` : 페이지를 저장할 수 있는 페이지 프레임의 갯수를 늘려도 page fault가 더 많이 발생하는 모순이 존재한다.

**최적 페이지 교체(Optimal Page Replacement)**

앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체하는 알고리즘이다

- 장점
    - 알고리즘 중 가장 최적의 결과를 나타낸다(가장 낮은 페이지 부재율을 보장)
- 단점
    - 실제로 프로세스의 메모리 참조 계획을 미리 알 수 없다.

**LRU 페이지 교체(Least-Recently-Used)**

가장 오랬동안 사용되지 않은 페이지를 선택하여 교체한다. 최적 알고리즘의 근사 알고리즘이다.

- 특징
    - 대체적으로 FIFO 알고리즘 보다 우수하고, OPT 알고리즘보다는 떨어진다.

**LFU 페이지 교체(Least-Frequently-Used)**

참조횟수가 가장 적은 페이지를 교체하는 방법이다. 활발하게 사용되는 페이지는 참조 횟수가 많아질 거라는 가정에서 만들어진 알고리즘이다.

- 특징
    - 어떤 프로세스가 특정 페이지를 집중적으로 사용하다, 다른 기능을 사용하게 되면 더이상 사용하지 않아도 계속 메모리에 머물게 되어 초기 가정에 어긋나는 시점이 발생할 수 있다.
    - 최적(OPT) 페이지 교체를 제대로 근사하지 못하기 때문에, 잘 쓰이지 않는다.

**MFU 페이지 교체(Most-Frequently-Used)**

참조횟수가 가장 적은 페이지가 최근에 메모리에 올라왔고, 앞으로 계속 사용될 것이라는 가정에 기반한다.

- 특징
    - 최적 페이지 교체를 제대로 근사하지 못하기 때문에 잘 쓰이지 않는다.

---

REFERENCE

[https://blog.naver.com/whdgml1996/222195497775](https://blog.naver.com/whdgml1996/222195497775)

[https://velog.io/@hyun0310woo/7.-운영체제-인터럽트에-대해서](https://velog.io/@hyun0310woo/7.-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%EC%9D%B8%ED%84%B0%EB%9F%BD%ED%8A%B8%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9C)

[https://velog.io/@codemcd/인터럽트Interrupt-3ek4aww0xj](https://velog.io/@codemcd/%EC%9D%B8%ED%84%B0%EB%9F%BD%ED%8A%B8Interrupt-3ek4aww0xj)

[https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OS#프로세스와-스레드의-차이](https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OS#%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%99%80-%EC%8A%A4%EB%A0%88%EB%93%9C%EC%9D%98-%EC%B0%A8%EC%9D%B4)

[https://icksw.tistory.com/124](https://icksw.tistory.com/124)

---

REFERENCE

[https://blog.naver.com/whdgml1996/222195497775](https://blog.naver.com/whdgml1996/222195497775)

[https://velog.io/@hyun0310woo/7.-운영체제-인터럽트에-대해서](https://velog.io/@hyun0310woo/7.-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%EC%9D%B8%ED%84%B0%EB%9F%BD%ED%8A%B8%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9C)

[https://velog.io/@codemcd/인터럽트Interrupt-3ek4aww0xj](https://velog.io/@codemcd/%EC%9D%B8%ED%84%B0%EB%9F%BD%ED%8A%B8Interrupt-3ek4aww0xj)

[https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OS#프로세스와-스레드의-차이](https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/OS#%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%99%80-%EC%8A%A4%EB%A0%88%EB%93%9C%EC%9D%98-%EC%B0%A8%EC%9D%B4)
